{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data and extract features from labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Data/munged_df.csv', index_col='account_id')\n",
    "# df = pd.read_csv('./Data/vif_pruned_df.csv', index_col='account_id')\n",
    "feature_cols = list(df.columns[:-1])\n",
    "target_col = df.columns[-1] \n",
    "X_all = df[feature_cols]\n",
    "y_all = df[target_col] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_all = scaler.fit_transform(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 14946 samples.\n",
      "Testing set has 1661 samples.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# TODO: Shuffle and split the dataset into the number of training and testing points above\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all , \n",
    "                                                    y_all, \n",
    "                                                    stratify=y_all,\n",
    "                                                    test_size=0.1, \n",
    "                                                    random_state=1)\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-----------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |         C | \n",
      "    1 | 00m16s | \u001b[35m   0.05100\u001b[0m | \u001b[32m   0.0010\u001b[0m | \n"
     ]
    }
   ],
   "source": [
    "def svccv(C):\n",
    "    return cross_val_score(svm.LinearSVC(C=C, random_state=2),\n",
    "                           X_train, y_train, 'f1', cv=10).mean()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gp_params = {\"alpha\": 1e5}\n",
    "\n",
    "    svcBO = BayesianOptimization(svccv, {'C': (0.0001, 100)})\n",
    "    svcBO.explore({'C': [0.001, 0.01, 0.1]})\n",
    "\n",
    "    svcBO.maximize(n_iter=10, **gp_params)\n",
    "    print('SVC: %11.9f' % svcBO.res['max']['max_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = svcBO.res['max']\n",
    "svm_C = results['max_params']['C']\n",
    "print(rbf_C)\n",
    "print(rbf_tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = svm.LinearSVC(C=svm_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "y_score = clf.fit(X_train, y_train).decision_function(X_test)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_test, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "lw = 2\n",
    "plt.plot(recall, precision, lw=lw, color='navy',\n",
    "         label='Precision-Recall Curve')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel('Recall: Share of Customer Conversions Captured')\n",
    "plt.ylabel('Precision: Accuracy of Predicted Customer Conversions')\n",
    "plt.title('Precision-Recall of Customer Conversion: AUC={0:0.2f}'.format(average_precision))\n",
    "plt.show()\n",
    "# path = '/home/bsknight/Documents/Personal_Training_Git/Udacity/Udacity-Machine_Learning_Nanodegree/' + \\\n",
    "#        'Capstone_Project/Images'\n",
    "# savepath = os.path.join(path, 'exploratory_analysis-feature_means.png')\n",
    "# plt.savefig(savepath)\n",
    "# plt.clf()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
