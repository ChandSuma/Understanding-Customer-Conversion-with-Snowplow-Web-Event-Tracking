{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsknight/.local/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data and extract features from labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Data/munged_df.csv', index_col='account_id')\n",
    "# df = pd.read_csv('./Data/vif_pruned_df.csv', index_col='account_id')\n",
    "feature_cols = list(df.columns[:-1])\n",
    "target_col = df.columns[-1] \n",
    "X_all = df[feature_cols]\n",
    "y_all = df[target_col] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_all = scaler.fit_transform(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 13285 samples.\n",
      "Testing set has 3322 samples.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# TODO: Shuffle and split the dataset into the number of training and testing points above\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all , \n",
    "                                                    y_all, \n",
    "                                                    stratify=y_all,\n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=1)\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-----------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |         C | \n",
      "    1 | 00m04s | \u001b[35m   0.05028\u001b[0m | \u001b[32m   0.0010\u001b[0m | \n",
      "    2 | 00m03s | \u001b[35m   0.06911\u001b[0m | \u001b[32m   0.0100\u001b[0m | \n",
      "    3 | 00m03s | \u001b[35m   0.13493\u001b[0m | \u001b[32m   0.1000\u001b[0m | \n",
      "    4 | 00m03s | \u001b[35m   0.19566\u001b[0m | \u001b[32m  99.8994\u001b[0m | \n",
      "    5 | 00m03s |    0.16728 |   14.8722 | \n",
      "    6 | 00m03s |    0.18636 |   65.4668 | \n",
      "    7 | 00m03s | \u001b[35m   0.21570\u001b[0m | \u001b[32m  34.9912\u001b[0m | \n",
      "    8 | 00m03s | \u001b[35m   0.23197\u001b[0m | \u001b[32m  49.4438\u001b[0m | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-----------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |         C | \n",
      "    9 | 00m04s |    0.20582 |   99.9985 | \n",
      "   10 | 00m03s |    0.20582 |   99.9991 | \n",
      "   11 | 00m03s |    0.20582 |   99.9995 | \n",
      "   12 | 00m03s |    0.06003 |    0.0031 | \n",
      "   13 | 00m03s |    0.20582 |   99.9998 | \n",
      "   14 | 00m04s |    0.05188 |    0.0001 | \n",
      "   15 | 00m04s |    0.20582 |   99.9979 | \n",
      "   16 | 00m04s |    0.05000 |    0.0004 | \n",
      "   17 | 00m04s |    0.20582 |   99.9999 | \n",
      "   18 | 00m04s |    0.20582 |   99.9967 | \n",
      "SVC: 0.231966776\n"
     ]
    }
   ],
   "source": [
    "def svccv(C):\n",
    "    return cross_val_score(svm.LinearSVC(C=C, random_state=1),\n",
    "                           X_train, y_train, 'f1', cv=10, n_jobs=-1).mean()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gp_params = {\"alpha\": 1e5}\n",
    "\n",
    "    svcBO = BayesianOptimization(svccv, {'C': (0.0001, 100)})\n",
    "    svcBO.explore({'C': [0.001, 0.01, 0.1]})\n",
    "\n",
    "    svcBO.maximize(n_iter=10, **gp_params)\n",
    "    print('SVC: %11.9f' % svcBO.res['max']['max_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.4438101562\n"
     ]
    }
   ],
   "source": [
    "results = svcBO.res['max']\n",
    "svm_C = results['max_params']['C']\n",
    "print(svm_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = svm.LinearSVC(C=svm_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "y_score = clf.fit(X_train, y_train).decision_function(X_test)\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "average_precision = average_precision_score(y_test, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lw = 2\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(recall, precision, lw=lw, color='navy', label='Precision-Recall Curve')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel('Recall: Share of Customer Conversions Captured')\n",
    "plt.ylabel('Precision: Accuracy of Predicted Customer Conversions')\n",
    "plt.title('Linear SVM with Bayesian Optimization', y=1.05, fontsize=16)\n",
    "plt.suptitle('Precision-Recall AUC={0:0.2f}'.format(average_precision), y=0.92, fontsize=12)\n",
    "# plt.show()\n",
    "path = '/home/bsknight/Documents/Personal_Training_Git/Udacity/Udacity-Machine_Learning_Nanodegree/' + \\\n",
    "       'Capstone_Project/Images'\n",
    "savepath = os.path.join(path, 'optimized_Linear_SVM.png')\n",
    "plt.savefig(savepath)\n",
    "plt.clf()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
